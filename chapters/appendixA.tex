\chapter{Richiami teorici di statistica}
Nello studio di un fenomeno scientifico si hanno solitamente a disposizione le risorse necessarie per esaminarne una piccolissima parte. Si ha dunque la necessità di effettuare un \textit{rilevamento statistico} per poter raccogliere un \textit{campione} di dati che descriva un frammento del fenomeno che si vuole studiare. La statistica descrittiva cerca, a partire da questo campione, di elaborare informazioni sintetiche e significative, mentre la statistica inferenziale, utilizzando metodi e nozioni del calcolo delle probabilità, mira a fare previsioni sul futuro o estendere i risultati della statistica descrittiva a tutta la popolazione, e quindi al fenomeno intero.\\
		I test sono un potente strumento della statistica inferenziale e hanno come obiettivo quello di verificare la bontà di un'ipotesi. Il test del $\chi ^2$ in particolare è utilizzato per verificare che le frequenze dei valori osservati si adattino alle frequenze teoriche di una distribuzione di probabilità prefissata.\\ Verranno ora richiamate al lettore alcune nozioni fondamentali.\\
		\begin{defn}
		Siano $\mu \in \mathbb{R}$ e $\sigma \in \mathbb{R} ^+$, si chiama \textit{densità normale} o \textit{gaussiana} di parametri $\mu$ e $\sigma$ la funzione:
		\[ f(x) = \frac{1}{\sigma \sqrt{2\pi}}e^{-\frac{1}{2} ( x-\mu / \sigma )^2 } \quad x\in\mathbb{R}\]
		\end{defn}
		\noindent La legge di cui $f$ è una densità si indica con il simbolo $\mathcal{N}(\mu ,\sigma ^2)$; ogni variabile aleatoria avente
tale legge prende il nome di variabile aleatoria normale o gaussiana. La media o speranza di una distribuzione gaussiana è data da:
\[E[x]=\int_{-\infty}^{+\infty}x\cdot f(x)\, dx=\mu \]
Mentre la varianza è data da:
\[E[(x-\mu )^2]=\int_{-\infty}^{+\infty}(x-\mu )^2 \cdot f(x)\, dx=\sigma ^2 \]
Nella famiglia delle leggi normali particolare rilevanza ha la $\mathcal{N}(0 ,1)$, chiamata anche \textit{legge normale standard} o \textit{gaussiana standard}, che ha per densità:
\[ f_{\mathcal{N}}(x) = \frac{1}{\sqrt{2\pi}}e^{-{x^2}/{2}} \quad x\in\mathbb{R}\]
Si passerà ora alla definizione della funzione $\Gamma$ di Eulero che comparirà nella funzione di distribuzione del $\chi ^2$.	
		\begin{defn}
		 Sia $\alpha > 0$ un numero reale. La funzione \textit{Gamma di Eulero} è definita come:
			\[\Gamma(\alpha)=\int_{0}^{+\infty}t^{\alpha-1}e^{-x}\, dt\]
			Si può inoltre notare che integrando per parti si ottiene:
			\[\Gamma(x+1)=x\cdot \Gamma(x)\]
			e poiché $\Gamma(1)=1$ la funzione può essere considerata un'estensione del fattoriale nel continuo, da cui segue che:
			\[\Gamma(x)=(x-1)!\]
		\end{defn}
		\noindent Si può ora definire la variabile aleatoria $\chi ^ 2$ e la sua distribuzione.
		\begin{defn}
		Siano $X_1,\ldots , X_n$ \textit{n} variabili aleatorie indipendenti tutte con densità normale standard $\mathcal{N}(0,1)$
		La variabile aleatoria $\chi ^ 2$ ad \textit{n} gradi di libertà è definita come:
		\[\chi ^ 2(n) = \sum_{i=1}^n X^2_i\]
		e in particolare una variabile aleatoria $x^2$ con distribuzione $\chi ^{2}(n)$ ha densità di probabilità:
		\[f_{n}(x)=C_n x^{\frac{n-2}{2}}e^{x / 2} \quad \mathrm{con} \quad C_n=\frac{1}{2^{n / 2}\Gamma(\frac{n}{2})} \]
		\end{defn}
		\noindent Si può quindi definire il test del $\chi ^2$ per una distribuzione. Si supponga di voler fare un esperimento che abbia come obiettivo l'osservazione di \textit{n} possibili eventi $E_1, \ldots , E_n$, e che per ognuno di questi eventi si registrino le occorrenze $o_1, \ldots , o_n$. Si supponga inoltre di poter determinare le occorrenze teoriche $e_1, \ldots , e_n$ di tali eventi. Per stabilire se le differenze fra le occorrenze osservate quelle teoriche siano significative, e quindi ci sia il bisogno di rifiutare le ipotesi che hanno permesso il calcolo delle $e_i$, si usa la quantità:
		
			\[S=\sum^{n}_{i=0}\frac{(o_i-e_i)^2}{e_i}\]
			che viene ancora considerata una variabile aleatoria $\chi ^ 2$, poiché per $o_i$ (e quindi $e_i$) grande, esse tendono ad essere variabili gaussiane e quindi $S$ tende ad una $\chi ^ 2$. I gradi di libertà stavolta risultano però essere $n-m-1$ dove $n$ è il numero degli eventi possibili, \textit{m} il numero di parametri utilizzato per calcolare gli $e_i$; inoltre vi è la perdita di un ulteriore grado di libertà poiché deve essere anche soddisfatta la relazione:
			\[\sum_{i=1}^n o_i = N \quad \mathrm{con} \: N \: \mathrm{numero} \:  \mathrm{totale} \: \mathrm{delle} \: \mathrm{osservazioni}\]
\newpage